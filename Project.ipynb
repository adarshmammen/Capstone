{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "consumer_key = \"KQ6yHFrCxvqWtueT2ns0Yss5u\"\n",
    "consumer_secret = \"9zxXNLKy1cJ66RhULnoXAx0O0RaFcAYBJQcIpP5YEU7SaRpQZs\"\n",
    "access_key = \"404816384-QYG3ORHKly19S1rVxnQjl36pbJP1OLrD7vrtTkEk\"\n",
    "access_secret = \"5oxR9HEFR3SfF21AMC7t1wNAdK5mUB4owZDFhnUJMUcvC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 766079914034552831\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 754905389188190207\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 726570030754848772\n",
      "...799 tweets downloaded so far\n",
      "getting tweets before 696501979565182976\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 661750552909475839\n",
      "...1199 tweets downloaded so far\n",
      "getting tweets before 622798131286163455\n",
      "...1399 tweets downloaded so far\n",
      "getting tweets before 597305688008892415\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 570288482914070527\n",
      "...1799 tweets downloaded so far\n",
      "getting tweets before 545453755949662208\n",
      "...1999 tweets downloaded so far\n",
      "getting tweets before 527506593408380927\n",
      "...2199 tweets downloaded so far\n",
      "getting tweets before 512508897387884543\n",
      "...2399 tweets downloaded so far\n",
      "getting tweets before 486214205075628031\n",
      "...2599 tweets downloaded so far\n",
      "getting tweets before 455462157963251711\n",
      "...2799 tweets downloaded so far\n",
      "getting tweets before 438478494721261567\n",
      "...2999 tweets downloaded so far\n",
      "getting tweets before 422220923404832767\n",
      "...3199 tweets downloaded so far\n",
      "getting tweets before 409078935075704831\n",
      "...3224 tweets downloaded so far\n",
      "getting tweets before 406581970194673663\n",
      "...3224 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "\n",
    "    alltweets = []\n",
    "\n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print \"getting tweets before %s\" % (oldest)\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print \"...%s tweets downloaded so far\" % (len(alltweets))\n",
    "\n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    \n",
    "    #write the csv\n",
    "    with open('%s_tweets.csv' % screen_name, 'wb') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "        writer.writerows(outtweets)\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_all_tweets(\"houseofcoates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After obtaining the CSV file, we proceed to extract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](Images/fig1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](Images/fig2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
